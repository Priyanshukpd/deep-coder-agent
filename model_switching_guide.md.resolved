# Model Switching & Future Scaling ðŸ§ 

The God Mode Agent is designed to be **Model Agnostic**.

## 1. Switching Models on Together AI (Supported Now)
You can instantly switch the underlying model by setting the `TOGETHER_MODEL` environment variable. No code changes required.

```bash
# Switch to Llama 3 (70B)
export TOGETHER_MODEL="meta-llama/Llama-3-70b-chat-hf"

# Switch to DeepSeek
export TOGETHER_MODEL="deepseek-ai/deepseek-coder-33b-instruct"

# Switch to Mixtral
export TOGETHER_MODEL="mistralai/Mixtral-8x7B-Instruct-v0.1"
```

**Recommended Models:**
*   `Qwen/Qwen2.5-Coder-32B-Instruct` (Fast, Good at code)
*   `meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo` (High intelligence)
*   `deepseek-ai/DeepSeek-V3` (State of the art open model)

## 2. Adding New Providers (Claude 4.5, GPT-5, Gemini 3)
To support models outside of Together AI (like Anthropic or OpenAI), we implement the **Provider Adapter Pattern**.

### Step 1: Create a new Provider Class
Create `agent/core/anthropic_provider.py`:

```python
class AnthropicProvider:
    def __init__(self, config):
        self.client = anthropic.Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])

    def complete(self, messages, ...):
        # Translate OpenAI format to Anthropic format
        # Call API
        # Return CompletionResult
```

### Step 2: Update Config
Modify [agent/config.py](file:///Users/munishm/Documents/god-mode-agent/agent/config.py):
```python
class AgentConfig:
    provider: str = "together" # or "anthropic", "openai"
```

### Step 3: Factory Pattern
Update [TaskExecutor](file:///Users/munishm/Documents/god-mode-agent/agent/core/task_executor.py#189-1482) to select the provider:
```python
if config.provider == "anthropic":
    self._provider = AnthropicProvider(config)
else:
    self._provider = TogetherProvider(config)
```

This architecture ensures that when **GPT-6** or **Claude 5** drops, you only need to write one adapter file to upgrade the entire agent.
